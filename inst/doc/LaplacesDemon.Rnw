\documentclass[a4paper]{article}
\usepackage{Sweave}
\usepackage{amsmath}
\usepackage{ulem}
\usepackage{url}

%\VignetteIndexEntry{LaplacesDemon Tutorial}
%\VignettePackage{LaplacesDemon}
%\VignetteDepends{LaplacesDemon}

% Definitions
\newcommand{\LaplacesDemon}{{\tt LaplacesDemon}}
\newcommand{\Rlan}{{\tt R}}
\setlength{\parindent}{0in}
\setlength{\parskip}{.1in}
\setlength{\textwidth}{140mm}
\setlength{\oddsidemargin}{10mm}

\title{{\tt LaplacesDemon} Tutorial}
\author{Byron Hall\\\textit{STATISTICAT,LLC}}
\begin{document}
\maketitle
\begin{abstract}
\LaplacesDemon{}, usually referred to as Laplace's 
Demon, is a contributed \Rlan{} package for Bayesian inference, and is 
freely available on the Comprehensive \Rlan{} Archive Network (CRAN).  
Laplace's Demon allows the choice of four MCMC algorithms to update a 
Bayesian model according to a user-specified model function.  The 
user-specified model function enables Bayesian inference for any model 
form, provided the user specifies the likelihood.  Laplace's Demon also 
attempts to assist the user by creating and offering \Rlan{} code, based 
on a previous model update, that can be copy/pasted and executed.  
Posterior predictive checks and many other features are included as well.  
Laplace's Demon seeks to be generalizable and user-friendly to 
Bayesians...especially Laplacians.
\end{abstract}

\textbf{Keywords.} Adaptive, AM, Bayesian Inference, Delayed Rejection, DR, 
DRAM, DRM, LaplacesDemon, Laplace's Demon, Markov chain Monte Carlo, MCMC, 
Metropolis, R, Random Walk, Random-Walk, STATISTICAT.

\textbf{Disclaimer.} Demonic references are used only to add flavor to the 
software and its use, and in no way endorse beliefs in demons.

<<echo=false>>=
options(width=75)
@

\section{Introduction}
Bayesian inference is named after Reverend Thomas Bayes (1702-1761) for 
developing Bayes' theorem, which was published posthumously after his 
death in 1763.  This was the first instance of what would be called 
inverse probability.

Unaware of Bayes, Pierre-Simon Laplace (1749-1827) independently 
developed Bayes' theorem and first published his version in 1774, eleven 
years after Bayes, in one of Laplace's first major works (Laplace, 1774, 
p.366-367).  In 1812, Laplace (1749-1827) introduced a host of new ideas 
and mathematical techniques in his book, \uline{Theorie Analytique des 
Probabilites}.  Before Laplace, probability theory was solely concerned 
with developing a mathematical analysis of games of chance. Laplace 
applied probabilistic ideas to many scientific and practical problems.  
Although Laplace is not the father of probability, Laplace may be 
considered the father of the field of probability.

In 1814, Laplace published his ``Essai philosophique sur les probabilites'', 
which introduced a mathematical system of inductive reasoning based on 
probability.  In it, the Bayesian interpretation of probability was 
developed independently by Laplace, much more thoroughly than Bayes, so 
some ``Bayesians'' refer to Bayesian inference as Laplacian inference.  This 
is a translation of a quote in the introduction to this work:

\begin{quote}
``We may regard the present state of the universe as the effect of its 
past and the cause of its future.  An intellect which at a certain moment 
would know all forces that set nature in motion, and all positions of all 
items of which nature is composed, if this intellect were also vast enough 
to submit these data to analysis, it would embrace in a single formula the 
movements of the greatest bodies of the universe and those of the tiniest 
atom; for such an intellect nothing would be uncertain and the future just 
like the past would be present before its eyes'' (Laplace, 1814).
\end{quote}

The `intellect' has been referred to by future biographers as Laplace's 
Demon.  In this quote, Laplace expresses his philosophical belief in hard 
determinism and his wish for a computational machine that is capable of 
estimating the universe.

This article is an introduction to an \Rlan{} package called 
\LaplacesDemon{}, which was designed without consideration for hard 
determinism, but instead with a lofty goal toward facilitating 
high-dimensional Bayesian (or Laplacian) inference, posing as its own 
intellect that is capable of impressive analysis.  The \LaplacesDemon{} 
\Rlan{} package is often referred to as Laplace's Demon. This article 
guides the user through installation, data, specifying a model, initial 
values, updating Laplace's Demon, summarizing and plotting output, 
posterior predictive checks, general suggestions, discusses independence 
and observability, covers details of the algorithm, software comparisons, 
discusses large data sets and speed, explains future goals, and presents 
references.

Herein, it is assumed that the reader has basic familiarity with Bayesian 
inference, numerical approximation, and \Rlan{}.  If any part of this 
assumption is violated, then suggested sources include Gelman et al. (2004) 
and Crawley (2007).

To wit, it is suspected that if Laplace's Demon actually existed, then 
from time to time it would chant:

\begin{quote}
\textit{One package to rule them all,}

\textit{One package to find them,}

\textit{One package to bring them all and in the darkness bind them}
\end{quote}

\section{Installation}
To obtain Laplace's Demon, simply open \Rlan{} and install the 
\LaplacesDemon{} package from a CRAN mirror:

<<eval=FALSE>>=
install.packages("LaplacesDemon")
@ 

A goal in developing Laplace's Demon was to minimize reliance on other 
packages or software.  Therefore, the usual \texttt{dep=TRUE} argument 
does not need to be used, because \LaplacesDemon{} does not depend on 
anything other than base \Rlan{}.  Once installed, simply use the 
\texttt{library} or \texttt{require} function in \Rlan{} to activate 
the \LaplacesDemon{} package and load its functions into memory:

<<>>=
library(LaplacesDemon)
@ 

Although Laplace's Demon is freely available, a software license restricts 
it from commercial use, except when a license is purchased from 
STATISTICAT, LLC\footnote{To obtain a license, send an email to 
\texttt{statisticat@gmail.com} or visit 
\url{http://www.statisticat.com/}.}.

\section{Data}
Laplace's Demon requires data that is specified in a list.  As an example, 
there is a data set called \texttt{demonsnacks} that is provided with the 
\LaplacesDemon{} package.  For no good reason, other than to provide an 
example, the log of \texttt{Calories} will be fit as an additive, linear 
function of the remaining variables.  Since an intercept will be included, 
a vector of 1's is inserted into design matrix \textbf{X}.

<<>>=
data(demonsnacks)
N <- NROW(demonsnacks)
J <- NCOL(demonsnacks)
y <- log(demonsnacks$Calories)
X <- cbind(1, as.matrix(demonsnacks[,c(1,3:10)]))
for (j in 2:J) {X[,j] <- (X[,j] - mean(X[,j])) / (2*sd(X[,j]))}
parm.names <- rep(NA,J+1)
for (j in 1:J) {parm.names[j] <- paste("beta[",j,"]",sep="")}
parm.names[J+1] <- "log.tau"
MyData <- list(J=J, X=X, parm.names=parm.names, y=y)
@

There are J=\Sexpr{J} independent variables (including the intercept), one 
for each column in design matrix \textbf{X}.  However, there are \Sexpr{J+1} 
parameters, since the residual precision, tau, must be included as well.  
The reason why it is called \texttt{log.tau} will be explained later.  
Each parameter must have a name specified in the vector 
\texttt{parm.names}, and parameter names must be included with the data.  
Also, note that each predictor has been centered and scaled, as per Gelman 
(2008).  This is a crude method of centering and scaling, where more 
elegant methods exist, but it is used here because it is easy to see how 
it is done.

\section{Specifying a Model}
To use Laplace's Demon, the user must specify a model.  Let's consider a 
simple linear regression, which is often denoted as:

$$
y_i \sim N(u_i, \sigma^2)
$$
$$
u_i = \beta X_i
$$

For a Bayesian model, the notation for the residual variance, 
$\sigma^2$, is often replaced with the residual precision, $\tau^-{}^1$. 
Prior probabilities are specified for $\beta$ and $\tau$:

$$
\beta_i \sim N(0, 0.001)
$$
$$
\tau \sim \Gamma(0.001, 0.001)
$$

To specify a model, the user must create a function called \texttt{Model}.  
Here is an example for a simple, linear regression model:

<<>>=
Model <- function(parm, Data)
     {
     ### Prior Parameters
     beta.mu <- rep(0,J)
     beta.tau <- rep(1.0E-3,J)
     tau.alpha <- 1.0E-3
     tau.beta <- 1.0E-3
     ### Parameters
     beta <- rep(0,J)
     for (j in 1:J) {beta[j] <- parm[j]}
     tau <- exp(parm[J+1])
     ### Log Prior Densities
     beta.prior <- rep(0,J)
     for (j in 1:J)
          {beta.prior[j] <- dnorm(beta[j], beta.mu[j],
               1/sqrt(beta.tau[j]), log=TRUE)}
     tau.prior <- dgamma(tau, tau.alpha, tau.beta, log=TRUE)
     ### Log-Posterior
     mu <- beta %*% t(X)
     LL <- sum(dnorm(y, mu, 1/sqrt(tau), log=TRUE))
     LP <- LL + sum(beta.prior) + tau.prior
     Modelout <- list(LP=LP, Dev=-2*LL, Monitor=c(tau,mu[1]), yhat=mu)
     return(Modelout)
     }
@ 

Laplace's Demon iteratively maximizes the log of the joint posterior 
density as specified in this \texttt{Model} function.  In Bayesian 
inference, the log of the joint posterior density is proportional to the 
sum of the log-likelihood and log of the prior densities:

$$
\log[p(\theta|y)] \propto \log[p(y|\theta)] + \log[p(\theta)]
$$

where $\theta$ is a set of parameters, $y$ is the data, $p(\theta|y)$ is 
the joint posterior density, $p(y|\theta)$ is the likelihood, and 
$p(\theta)$ is the set of prior densities.

During each iteration in which Laplace's Demon is maximizing the log of 
the joint posterior density, Laplace's Demon passes two arguments to 
\texttt{Model}: \texttt{parm} and \texttt{Data}, where \texttt{parm} is 
short for the set of parameters, and \texttt{Data} is the data.  These 
arguments are specified in the beginning of the function:

\texttt{Model <- function(parm, Data)}

Then, the Model function is evaluated and the log of the joint posterior 
density is calculated as \texttt{LP}, and returned to Laplace's Demon in a 
list called \texttt{Modelout}, along with the deviance (\texttt{Dev}), a 
vector (\texttt{Monitor}) of any variables desired to be monitored in 
addition to the parameters, and y[rep] (\texttt{yhat}) or replicates of 
y.  All arguments must be returned.  Even if there is no desire to observe 
the deviance and any monitored variable, a scalar must be placed in the 
second position of the \texttt{Modelout} list, and at least one element of 
a vector for a monitored variable.  This can be seen in the end of the 
function:

\texttt{LP <- LL + sum(beta.prior) + tau.prior}

\texttt{Modelout <- list(LP=LP, Dev=-2*LL, Monitor=c(tau,mu[1]), yhat=mu)}

\texttt{return(Modelout)}

The rest of the function specifies the prior parameters, parameters, log 
of the prior densities, and calculates the log-likelihood.

The prior parameters specify the parameters for the prior distributions.  
Since design matrix \textbf{X} has J=\Sexpr{J} independent variables 
(including the intercept), there are \Sexpr{J} \texttt{beta} parameters 
and a \texttt{tau} parameter for residual precision, the inverse of the 
variance.  Each of the \texttt{J beta} parameters will be distributed 
normally according to mean \texttt{beta.mu} and precision 
\texttt{beta.tau}, and the additional \texttt{tau} parameter will be 
gamma-distributed according to \texttt{tau.alpha} and \texttt{tau.beta}.  
Here are the specifications for the prior parameters:

\texttt{beta.mu <- rep(0,J)}

\texttt{beta.tau <- rep(1.0E-3,J)}

\texttt{tau.alpha <- 1.0E-3}

\texttt{tau.beta <- 1.0E-3}

Since Laplace's Demon passes a vector of parameters called \texttt{parm} 
to \texttt{Model}, the function needs to know which parameter is 
associated with which element of \texttt{parm}.  For this, the vector 
\texttt{beta} is declared, and then each element of \texttt{beta} is 
populated with the value associated in the corresponding element of 
\texttt{parm}.  The reason why \texttt{tau} is exponentiated will, again, 
be explained later.

\texttt{beta <- rep(0,J)}

\texttt{for (j in 1:J) {beta[j] <- parm[j]}}

\texttt{tau <- exp(parm[J+1])}

To work with the log of the prior densities and according to the assigned 
names of the parameters and prior parameters, they are specified as 
follows:

\texttt{beta.prior <- rep(0,J)}

\texttt{for (j in 1:J)}

\texttt{     {beta.prior[j] <- dnorm(beta[j], beta.mu[j], 1/sqrt(beta.tau[j]), log=TRUE)}}

\texttt{tau.prior <- dgamma(tau, tau.alpha, tau.beta, log=TRUE)}

It is important to reparameterize all parameters to be real-valued.  For 
example, a positive-only parameter such as variance should be transformed 
with a \texttt{log} function, and a proportion p can be transformed to the 
real line by a \texttt{logit} function, such as 
\texttt{logit(p) = log(p/(1-p))}.  Laplace's Demon will attempt to 
increase or decrease the value of each parameter to maximize \texttt{LP}, 
without consideration for the distributional form of the parameter.  In 
the above example, the residual precision \texttt{tau} receives a 
gamma-distributed prior of the form:

$$
\tau \sim \Gamma(0.001, 0.001)
$$

In this specification, \texttt{tau} cannot be negative.  By 
reparameterizing \texttt{tau} as 

\texttt{tau <- exp(parm[J+1])},

Laplace's Demon will increase or decrease \texttt{parm[J+1]}, which is 
effectively \texttt{log(tau)}).  Now it is possible for Laplace's Demon to 
decrease \texttt{log(tau)}) below zero without causing an error or 
violating its gamma-distributed specification.

Finally, everything is put together to calculate \texttt{LP}, the log of 
the joint posterior density.  The expectation vector \texttt{mu} is the 
inner product (\texttt{\%*\%}) of the vector \texttt{beta} and the 
transposed design matrix, \texttt{t(X)}.  Expectation vector \texttt{mu}, 
vector \texttt{y}, and scalar \texttt{tau} are used to estimate the sum 
of the log-likelihoods, where:

$$
y_i \sim N(u_i, \tau^-{}^1)
$$

and as noted before, the log of the joint posterior density is:

$$
\log[p(\theta|y)] \propto \log[p(y|\theta)] + \log[p(\theta)]
$$

\texttt{mu <- beta \%*\% t(X)}

\texttt{LL <- sum(dnorm(y, mu, 1/sqrt(tau), log=TRUE)}

\texttt{LP <- LL + sum(beta.prior) + tau.prior}

Specifying the model in the \texttt{Model} function is the most involved 
aspect for the user of Laplace's Demon.  But it has been designed so it is 
also incredibly flexible, allowing a wide variety of Bayesian models to be 
specified.

Missing values can be estimated in Laplace's Demon, but each missing value 
must be specified as a parameter in \texttt{Model} so that an initial 
value is assigned.

\section{Initial Values}
Laplace's Demon requires a vector of initial values for the parameters.  
Each initial value is a user-specified starting point for a parameter.  
In this example, there are \Sexpr{J+1} parameters, and with no prior 
knowledge, it is a good idea to set them equal to zero or use a random 
function.  The first \Sexpr{J} parameters, the \texttt{beta} parameters, 
have been set equal to zero, and the remaining parameter, 
\texttt{log.tau}, has been set equal to \texttt{log(1)}, which is equal to 
zero; this visually reminds me that I am working with the log of 
\texttt{tau}, rather than \texttt{tau}.  The order of the elements of the 
vector of initial values must match the order of the parameters associated 
with each element of \texttt{parm} passed to \texttt{Model}.

<<>>=
Initial.Values <- c(rep(0,J), log(1))
@ 

\section{Laplace's Demon}
Compared to specifying the model in \texttt{Model}, the actual use of 
Laplace's Demon is very easy.  Since Laplace's Demon is stochastic, or 
involves pseudo-random numbers, it's a good idea to set a 'seed' for 
pseudo-random number generation, so results can be reproduced.  Pick any 
number you like, but there's only one number appropriate for a demon:

<<>>=
set.seed(666)
@ 

As with any \Rlan{} package, the user can learn about a function by 
entering a question mark, followed by the name of the function.  To learn 
the details of the \LaplacesDemon{} function, enter:

\texttt{> ?LaplacesDemon} 

Here is one of many possible ways to begin:

<<eval=FALSE>>=
Fit <- LaplacesDemon(Model, Data=MyData, Adaptive=900, 
     Covar=NULL, DR=1, Initial.Values, Iterations=10000,
     Periodicity=10, Status=1000, Thinning=10)
@ 

In this example, an output object called \texttt{Fit} will be created as a 
result of using the \LaplacesDemon{} function.  \texttt{Fit} is an object 
of class \texttt{demonoid}, which means that since it has been assigned a 
customized class, other functions have been custom-designed to work with 
it.  Laplace's Demon offers four MCMC algorithms (which are explained in 
the \textit{Details} section).  The above example declares the Delayed 
Rejection Adaptive Metropolis (DRAM) algorithm.

The above example tells the \LaplacesDemon{} function to maximize the 
user-specified \texttt{Model} function, given a data set called 
\texttt{MyData}, and according to several settings.  
\begin{itemize}
\item The \texttt{Adaptive=900} argument indicates that a non-adaptive 
  MCMC algorithm will begin, and that it will become adaptive at the 900th 
  iteration.  Beginning with the 900th iteration, the MCMC algorithm will 
  estimate the proposal variance or covariance based on the history of the 
  chains.
\item The \texttt{Covar=NULL} argument indicates that a user-specified 
  variance vector or covariance matrix has not been supplied, so the 
  algorithm will begin with its own estimate.
\item The \texttt{DR=1} argument indicates that delayed rejection will 
  occur, such that when a proposal is rejected, an additional proposal 
  will be attempted, thus potentially delaying rejection of proposals.
\item The \texttt{Initial.Values} argument requires a vector of initial 
  values for the parameters.
\item The \texttt{Iterations=10000} argument indicates that 
  \LaplacesDemon{} will update 10,000 times before completion.
\item The \texttt{Periodicity=10} argument indicates that once adaptation 
  begins, the algorithm will adapt every 10 iterations.
\item The \texttt{Status=1000} argument indicates that a status message 
  will be printed to the \Rlan{} console every 1,000 iterations.
\item Finally, the \texttt{Thinning=10} argument indicates that only 
  every nth iteration will be retained in the output, and in this case, 
  every 10th iteration will be retained.
\end{itemize}

By running the \LaplacesDemon{} function, the following output was 
obtained:

<<>>=
Fit <- LaplacesDemon(Model, Data=MyData, Adaptive=900, 
     Covar=NULL, DR=1, Initial.Values, Iterations=10000,
     Periodicity=10, Status=1000, Thinning=10)
@ 

Laplace's Demon finished quickly, though it had a small data set 
(N=\Sexpr{NROW(X)}), few parameters (K=\Sexpr{J+1}), and the model was 
very simple.  At each status of \Sexpr{Fit$Status} iterations, the 
proposal was multivariate, so it did not have to resort to independent 
proposals.  The output object, \texttt{Fit}, was created as a list.  As 
with any \Rlan{} object, use \texttt{str()} to examine its contents:

<<eval=FALSE>>=
str(Fit)
@ 

To access any of these values in the output object \texttt{Fit}, simply 
append a dollar sign and the name of the item.  For example, here is how 
to access the observed acceptance rate:

<<>>=
Fit$Acceptance.Rate
@ 

\section{Summarizing Output}
The output object, \texttt{Fit}, has many components.  The (copious) 
contents of \texttt{Fit} can be printed to the screen with the usual 
\Rlan{} functions:

<<eval=FALSE>>=
Fit
print(Fit)
@ 

Both return the same output, which is:

<<>>=
Fit
@ 

Several items are labeled as \texttt{NOT SHOWN HERE}, due to their size, 
such as the covariance matrix \texttt{Covar} or the stationary posterior 
samples \texttt{Posterior2}.  As usual, these can be printed to the screen 
by appending a dollar sign, followed by the desired item, such as:

<<eval=FALSE>>=
Fit$Posterior2
@ 

Although a lot can be learned from the above output, notice that it 
completed \Sexpr{Fit$Iterations} iterations of \Sexpr{J+1} variables in 
\Sexpr{round(Fit$Minutes,2)} minutes.  Of course this was fast, since there were 
only \Sexpr{NROW(X)} records, and the form of the specified model was 
simple.  As discussed later, Laplace's Demon does better than most other 
MCMC software with large numbers of records, such as 100,000.

In \Rlan{}, there is usually a \texttt{summary} function associated with 
each class of output object.  The \texttt{summary} function usually 
summarizes the output.  For example, with frequentist models, the 
\texttt{summary} function usually creates a table of parameter estimates, 
complete with p-values.

Since this is not a frequentist package, p-values are not part of any 
table, and the marginal posterior distributions of the parameters and 
other variables have already been summarized in \texttt{Fit}, there is no 
point to have an associated \texttt{summary} function.  Going one more 
step toward useability, \LaplacesDemon{} has a \texttt{Consort} function, 
where the user consorts with Laplace's Demon about the output object.  For 
example:

<<eval=FALSE>>=
Consort(Fit)
@ 

This produces two kinds of output.  The first section is identical to 
\texttt{print(Fit)}, but by consorting with Laplace's Demon, it also 
produces a second section called \texttt{Demonic Suggestion}.

<<>>=
Consort(Fit)
@ 

The \texttt{Demonic Suggestion} is a very helpful section of output.  
When Laplace's Demon was developed initially in late 2010, there were not 
to my knowledge any tools of Bayesian inference that make suggestions to 
the user.

Before making its \texttt{Demonic Suggestion}, Laplace's Demon considers 
and presents five conditions: the algorithm, acceptance rate, MCSE, 
effective sample size, and stationarity.  There are 48 combinations of 
these five conditions, though many combinations lead to the same 
conclusion.  In addition to these conditions, there are other suggested 
values, such as a recommended number of iterations or values for the 
\texttt{Periodicity} and \texttt{Status} arguments.  The suggested value 
for \texttt{Status} is seeking to print a status message every minute 
when the expected time is longer than a minute, and is based on the time 
in minutes it took, the number of iterations, and the recommended number 
of iterations.  This estimate is fairly accurate for non-adaptive 
algorithms, and is hard to estimate for adaptive algorithms.  But, back to 
the really helpful part...

If these five conditions are not satisfactory, then Laplace's Demon is not 
appeased, and suggests it should continue updating, and that the user 
should copy/paste and execute its suggested \Rlan{} code.  Here are the 
criteria it measures against.  The final algorithm must be non-adaptive, 
so that the Markov Property holds (this is covered in the \textit{Details} 
section).  The acceptance rate is considered satisfactory if it is within 
the interval [15\%,50\%].  MCSE is considered satisfactory for each target 
distribution if it is less than 6.27\% of the standard deviation of the 
target distribution.  This allows the true mean to be within 5\% of the 
area under a normal distribution around the estimated mean.  The effective 
sample size is considered satisfactory for each target distribution if it 
is at least 100, which is usually enough to describe 95\% probability 
intervals.  And finally, each variable must be estimated as stationary.

Notice that since stationarity has been estimated beginning with the 
\Sexpr{Fit$Rec.BurnIn.Thinned}st iteration, the suggested \Rlan{} code 
changes from \texttt{Adaptive=900} to \texttt{Adaptive=0}.  The suggestion 
is to abandon the adaptive MCMC algorithm in favor of a non-adaptive 
algorithm, specifically a Random-Walk Metropolis (RWM).  It is also 
replacing the initial values with the latest values of the parameter 
chains, and is suggesting to begin with the latest covariance matrix.  
Some of the arguments in the suggested \Rlan{} code seem excessive, such 
as \texttt{Iterations=270000} and \texttt{Thinning=270}.  For the sake of 
the example, the suggested \Rlan{} code will be run:

<<>>=
Initial.Values <- Fit$Posterior1[Fit$Thinned.Samples,]
Fit <- LaplacesDemon(Model, Data=MyData, Adaptive=0,
     Covar=Fit$Covar, DR=0, Initial.Values, Iterations=270000,
     Periodicity=0, Status=23970, Thinning=270)
@ 

Next, the user consorts with Laplace's Demon:

<<>>=
Consort(Fit)
@ 

In \Sexpr{round(Fit$Minutes,2)} minutes, Laplace's Demon updated 
\Sexpr{Fit$Iterations} iterations, retaining every \Sexpr{Fit$Thinning}th 
iteration due to thinning, and reported an acceptance rate of 
\Sexpr{round(Fit$Acceptance.Rate,3)}, which is low enough to trigger a 
suggestion to continue updating.  However, notice that all other criteria 
have been met: MCSE's are sufficiently small, effective size is 
sufficiently large, and stationarity was estimated beginning with the 
first iteration.

Notice \texttt{DR=1} in the suggested \Rlan{} code.  Together with 
\texttt{Adaptive=0}, this indicates that a Delayed Rejection Metropolis 
(DRM) algorithm is suggested.  DRM is discussed in the \textit{Details} 
section, but here it is enough to state that in the case of a rejected 
proposal, the DRM algorithm will make a second proposal before simply 
moving on to the next iteration.  This serves to increase the acceptance 
rate, and is obviously why Laplace's Demon suggests DRM.

The low acceptance rate suggests that the proposal distribution may not be 
optimal, and that the chains may not have mixed well.  Even though 
Laplace's Demon has not been appeased due to the acceptance rate, 
everything else looks good.  Since the algorithm was RWM, the Markov 
property holds, so let's look at some plots.

\section{Plotting Output}
Laplace's Demon has a \texttt{plot.demonoid} function to enable its own
customized plots with \texttt{demonoid} objects.  The variable 
\texttt{BurnIn} (below) may be left as it is so it will show only the 
stationary samples (samples that are no longer trending), or set equal to 
one so that all samples can be plotted.  In this case, it will already be 
one, so I will leave it alone.  The function also enables the user to 
specify whether or not the plots should be saved as a .pdf file, and 
allows the user to limit the number of parameters plotted, in case the 
number is very large and only a quick glance is desired.

<<>>=
BurnIn <- Fit$Rec.BurnIn.Thinned
@ 
<<eval=FALSE>>=
plot(Fit, BurnIn, MyData, PDF=FALSE, Parms=Fit$Parameters)
@ 

\begin{figure}
\begin{center}
<<label=fig1,fig=TRUE,echo=FALSE>>=
par(mfrow=c(3,3))
for (j in 1:3){
     plot(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          type="l", xlab="Iterations", ylab="Value",
          main=MyData$parm.names[j])
     plot(density(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j]),
          main=MyData$parm.names[j])
     acf(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          main=MyData$parm.names[j])
     }
@  
\end{center}
\caption{Plots of Marginal Posterior Samples}
\end{figure}

\begin{figure}
\begin{center}
<<label=fig2,fig=TRUE,echo=FALSE>>=
par(mfrow=c(3,3))
for (j in 4:6){
     plot(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          type="l", xlab="Iterations", ylab="Value",
          main=MyData$parm.names[j])
     plot(density(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j]),
          main=MyData$parm.names[j])
     acf(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          main=MyData$parm.names[j])
     }
@  
\end{center}
\caption{Plots of Marginal Posterior Samples}
\end{figure}

\begin{figure}
\begin{center}
<<label=fig3,fig=TRUE,echo=FALSE>>=
par(mfrow=c(3,3))
for (j in 7:9){
     plot(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          type="l", xlab="Iterations", ylab="Value",
          main=MyData$parm.names[j])
     plot(density(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j]),
          main=MyData$parm.names[j])
     acf(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          main=MyData$parm.names[j])
     }
@  
\end{center}
\caption{Plots of Marginal Posterior Samples}
\end{figure}

\begin{figure}
\begin{center}
<<label=fig4,fig=TRUE,echo=FALSE>>=
par(mfrow=c(3,3))
for (j in 10:11){
     plot(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          type="l", xlab="Iterations", ylab="Value",
          main=MyData$parm.names[j])
     plot(density(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j]),
          main=MyData$parm.names[j])
     acf(Fit$Posterior1[BurnIn:Fit$Thinned.Samples,j],
          main=MyData$parm.names[j])
     }
plot(Fit$Deviance[BurnIn:length(Fit$Deviance)],
     type="l", xlab="Iterations", ylab="Value", main="Deviance")
plot(density(Fit$Deviance[BurnIn:length(Fit$Deviance)]),
     main="Deviance")
acf(Fit$Deviance[BurnIn:length(Fit$Deviance)],
     main="Deviance")
@  
\end{center}
\caption{Plots of Marginal Posterior Samples}
\end{figure}

\begin{figure}
\begin{center}
<<label=fig5,fig=TRUE,echo=FALSE>>=
par(mfrow=c(2,3))
JJ <- NCOL(Fit$Monitor); nn <- NROW(Fit$Monitor)
for (j in 1:JJ){
     plot(Fit$Monitor[BurnIn:nn,j],
          type="l", xlab="Iterations", ylab="Value",
          main="Monitor")
     plot(density(Fit$Monitor[BurnIn:nn,j]),
          main="Monitor")
     acf(Fit$Monitor[BurnIn:nn,j],
          main="Monitor")
     }
@  
\end{center}
\caption{Plots of Marginal Posterior Samples}
\end{figure}

There are 3 plots for each parameter, the deviance, and each monitored 
variable (which in this example are \texttt{tau} and \texttt{mu[1]}).  
The leftmost plot is a trace-plot, showing the history of the value of the 
parameter according to the iteration.  The middlemost plot is a kernel 
density plot.  The rightmost plot is an ACF or autocorrelation function 
plot, showing the autocorrelation at different lags.  The chains look 
stationary (do not exhibit a trend), the kernel densities look Gaussian, 
and the ACF's show low autocorrelation.

If all is well, then the Markov chains should be studied with MCMC 
diagnostics, and finally, further assessments of model fit should be 
estimated with posterior predictive checks, showing how well (or poorly) 
the model fits the data.  When the user is satisfied, marginal posterior 
samples may be used for inference.

When predicting the logarithm of \texttt{y} (Calories) with the 
\texttt{demonsnacks} data, the best fitting variables are \texttt{beta[6]} 
(Sodium), \texttt{beta[7]} (Total.Carbohydrate), and \texttt{beta[10]} 
(Protein).  Overall, Laplace's Demon seems to have done well, eating 
\texttt{demonsnacks} for breakfast.

\section{Posterior Predictive Checks}
A posterior predictive check is a method to assess discrepancies between 
the model and the data (Gelman, Meng, \& Stern, 1996).  To perform 
posterior predictive checks with Laplace's Demon, simply use the 
\texttt{predict} function:

<<>>=
Pred <- predict(Fit, Model, MyData)
@ 

This creates \texttt{Pred}, which is an object of class 
\texttt{demonoid.ppc} (where ppc is short for posterior predictive check) 
that is a list which contains \texttt{y} and \texttt{yhat}.  If the data 
set that was used to estimate the model is supplied in \texttt{predict}, 
then replicates of \texttt{y} (also called y[rep]) are estimated.  If a 
new data set is supplied in \texttt{predict}, then new, unobserved 
instances of \texttt{y} (called y[new]) are estimated.  Note that with new 
data, a \texttt{y} vector must still be supplied, and if unknown, can be 
set to something sensible such as the mean of the \texttt{y} vector in the 
model.

The posterior predictive distribution may be summarized:

<<eval=FALSE>>=
summary(Pred)
@ 

The \texttt{summary} consists of: \texttt{Chi.Square} is a chi-square 
model fit statistic considering \texttt{y} and \texttt{yhat}.  
\texttt{Concordance} is a scalar value that indicates the percentage of 
records of \texttt{y} that are within the probability interval 
[2.5\%,97.5\%] of y[rep].  \texttt{Summary} is a n x 7 matrix with a 
row for each record of \texttt{y}, and 7 columns: y, Mean, SD, LB, 
Median, UB, and p.value.  The \texttt{p.value} is the posterior 
predictive p-value, as described in Gelman et al. (1996).  Lastly, 
\texttt{yhat} is a n x s matrix with a row for each record of \texttt{y} 
and a column for each sample of the marginal posterior samples.

The \texttt{predict} function calls the \texttt{Model} function once for 
each set of stationary samples in \texttt{Fit\$Posterior2}.  Each set of 
samples is used to calculate \texttt{mu}, which is the expectation of 
\texttt{y}, and \texttt{mu} is reported here as \texttt{yhat}.  When there 
are few discrepancies between \texttt{y} and y[rep], the model is 
considered to fit the data well.

Since \texttt{Pred\$yhat} is a large (39 x 1000) matrix, let's look at the 
summary of it:

<<>>=
summary(Pred)
@ 

\texttt{Chi.Square} can be interpreted as a traditional chi-square for 
model fit.  As the value becomes larger, the model exhibits worse fit.

\texttt{Concordance} is a summary of the posterior predictive p-values 
for all elements of \texttt{y}, indicating a percentage of how many 
records had \texttt{y} within the 95\% probability interval of 
\texttt{yhat}.  In this case, roughly 
\Sexpr{round(summary(Pred)$Concordance,0)}\% of the time, \texttt{y} is 
within the 95\% probability interval of yhat.  All models are wrong, but 
some fit better than others.  Every statistician should strive for the 
best fitting model, but a good and arbitrary goal is to attempt to 
achieve at least 95\% concordance.  This suggests that the model should 
be attempted again under different conditions, such as using different 
predictors, or specifying a different form to the model.

The last part of the summarized output reports \texttt{y}, information 
about the distribution of \texttt{yhat}, and the posterior predictive 
p-value.  The mean prediction of \texttt{y[1]}, or yrep[1], given the 
model and data, is \Sexpr{round(summary(Pred)$Summary[1,2],3)}.  Most 
importantly, \texttt{p.value[1]} is 
\Sexpr{round(summary(Pred)$Summary[1,7],3)}, indicating that 
\Sexpr{round(summary(Pred)$Summary[1,7]*100,1)}\% of the time, 
\texttt{yhat[1,]} was greater than \texttt{y[1]}, or that 
\texttt{y[1]} is close to the mean \texttt{yhat[1,]}.  Contrast this 
with the 6th record, where 
\texttt{y[6]}=\Sexpr{round(summary(Pred)$Summary[6,1],3)} and 
\texttt{p.value[6]}=\Sexpr{round(summary(Pred)$Summary[6,7],3)}.  
Therefore, \texttt{yhat[6,]} was not a good replication of \texttt{y[6]}, 
because the distribution of \texttt{yhat[6,]} is always greater than 
\texttt{y[6]}.  While \texttt{y[6]} is 
\Sexpr{round(summary(Pred)$Summary[6,1],3)}, \texttt{yhat[6,]} 
has a mean of \Sexpr{round(summary(Pred)$Summary[6,2],3)} and is within 
the 95\% probability interval 
[\Sexpr{round(summary(Pred)$Summary[6,4],3)}, 
\Sexpr{round(summary(Pred)$Summary[6,6],3)}].  Clearly, the 95\% 
probability interval of \texttt{yrep[6,]} is above \texttt{y[6]} 100\% of 
the time, indicating a strong discrepancy between the model and data, in 
this case.

The last part of this summary may be viewed graphically as well.  Rather 
than observing plots for each of \Sexpr{NROW(Pred$yhat)} records or rows, 
only the first 9 will be shown here:

<<eval=FALSE>>=
plot(Pred, Rows=c(1:9))
@ 

\begin{figure}
\begin{center}
<<label=fig6,fig=TRUE,echo=FALSE>>=
par(mfrow=c(3,3))
for (j in 1:9){
     plot(density(Pred$yhat[j,]),
          main=paste("Post. Pred. Plot of yhat[", j,
               ",]", sep=""), sub="Black=Density, Blue=y")
     abline(v=Pred$y[j], col="blue")
     }
@  
\end{center}
\caption{Plots of Marginal Posterior Samples}
\end{figure}

These posterior predictive checks indicate that there is plenty of room to 
improve this model.

\section{General Suggestions}
Following are general suggestions on how best to use Laplace's Demon:

\begin{itemize}
\item As suggested by Gelman (2008), continuous predictors should be 
  centered and scaled.  Here is an explicit example in \Rlan{} of how to 
  center and scale a single predictor called \texttt{x01}: 
  \texttt{x01.cs <- (x01 - mean(x01)) / (2*sd(x01))}.
\item Do not forget to reparameterize any bounded parameters in 
  \texttt{Model} to be real-valued.
\item MCMC is a stochastic method of numerical approximation, and as such, 
  results may differ with each run due to the use of pseudo-random number 
  generation.  It is good practice to set a seed so that each update of 
  the model may be reproduced.  Here is an example in \Rlan{}: 
  \texttt{set.seed(666)}.
\item Once a model has been specified in \texttt{Model}, it may be 
  tempting to specify a large number of iterations and thinning in 
  \LaplacesDemon{}, and simply let the model update a long time, hoping 
  for convergence.  Instead, it is wise to begin with few iterations such 
  as \texttt{Iterations=20}, set \texttt{Adaptive=0} (preventing 
  adaptation), and set \texttt{Thinning=1}.  User-error in specifying the 
  \texttt{Model} function will be frustrating otherwise.
\item After studying updates with few iterations, the first ``actual'' 
  update should be long enough that adaptation begins to occur, and that 
  enough iterations occur after the first adaptation to allow the user to 
  study the adaptation.  In the supplied example, adaptation was allowed to 
  begin at the 900th iteration (\texttt{Adaptive=900}), but also occurred 
  with \texttt{Periodicity=10}, so every 10th iteration, adaptation 
  occurred.  It is also wise to use delayed rejection to assist with the 
  acceptance rate when the algorithm may begin far from its solution, so 
  set \texttt{DR=1}.
\item If adaptation does not seem to improve estimation or the initial 
  movement in the chains is worse than expected, then consider changing 
  the initial values.  Initial values are most effective when the starting 
  points are close to the target distributions.  When initial values are 
  far enough away from the target distributions to be in low-probability 
  regions, the algorithm may take longer than usual, and will struggle 
  more as the proposal covariance matrix approaches near-singularity.  If 
  there is no information available to make a better selection, then 
  randomize the initial values.  Centered and scaled predictors also help 
  by essentially standardizing the possible range of the target 
  distributions.
\item If Laplace's Demon exhibits an unacceptably low acceptance rate 
  (say, arbitrarily, lower than 15\%) and is having a hard time exploring 
  after significant iterations, then investigate the latest proposal 
  covariance matrix by entering \texttt{Fit\$Covar}.  Chances are that the 
  diagonal, the variances, are large.  In this case, it may be best to set 
  \texttt{Covar=NULL} for the next time it continues to update, which will 
  begin by default with a scaled identity matrix that should get more 
  movement in the chains.  As is usual practice, the latest sampled values 
  should also replace the initial values, so it begins from the last point, 
  but with larger proposal variances.  The chains will mix better the 
  closer they get to their target distributions.  The user can confirm 
  that Laplace's Demon is making progress and moving overall in the right 
  direction by observing the trace-plot of the deviance.  If it is 
  decreasing run after run, then the model is continuously fitting better 
  and better, and one sign of convergence will be when the deviance seems 
  to become stationary or no longer shows a trend.
\item \texttt{Demonic Suggestion} is intended as an aid, not an 
  infallible replacement for critical thinking.  As with anything else, 
  its suggestions are based on assumptions, and it is the responsibility 
  of the user to check those assumptions.  For example, the 
  \texttt{Geweke.Diagnostic} may indicate stationarity (lack of a trend) 
  when it does not exist, and this most likely occurs when too few 
  thinned samples remain.  Or, the \texttt{Demonic Suggestion} may 
  indicate that the next update may need to run for a million iterations 
  in a complex model, requiring weeks to complete.  Is this really best 
  for the user?
\item Use a two-phase approach with Laplace's Demon, where the first phase 
  consists of using the AM or DRAM algorithm to achieve stationary samples 
  that seem to have converged to the target distributions (convergence can 
  never be determined with MCMC, but some instances of non-convergence can 
  be observed).  Once it is believed that convergence has occurred, 
  continue Laplace's Demon with \texttt{Adaptive=0} so that adaptation will 
  not occur.  The final samples should again be checked for signs of 
  non-convergence and, if satisfactory, used for inference.
\item The desirable number of final, thinned samples for inference depends 
  on the required precision of the inferential goal.  A good general goal 
  is to end up with 1,000 thinned samples, where the effective sample size 
  is at least 100.
\item Debates exist in MCMC literature as to whether to update one chain 
  or multiple chains with different, randomized initial values.  Laplace's 
  Demon is not designed to simultaneously update multiple chains, because 
  its algorithms are likely to produce multiple long chains, as opposed to 
  Gibbs sampling, which should converge faster when its conditions are 
  met.  Therefore, one long chain is suggested here.  Nonetheless, if 
  multiple chains are desired, then Laplace's Demon can be updated a 
  series of times, each beginning with different initial values, until 
  multiple output objects of class \texttt{demonoid} exist with stationary 
  samples, if time allows.
\end{itemize}

\section{Independence and Observability}
For the user, one set of advantages of Laplace's Demon compared to many 
other available methods is that it was designed with independence and 
observability in mind.  By independence, it is meant that a goal was to 
minimize the dependence on other software.  Laplace's Demon is performed 
completely within base \Rlan{} (though of course the \LaplacesDemon{} 
package is required).  From personal experience, I've used multiple 
packages to achieve goals before, and have been trapped when one of those 
packages failed to keep pace with other changes.

All functions in Laplace's Demon are written entirely in \Rlan{}, so the 
user can easily observe or manipulate the algorithm or functions.  For 
example, to print the code for \LaplacesDemon{} to the \Rlan{} console, 
simply enter:

<<eval=FALSE>>=
LaplacesDemon
@ 

\section{Details}
Laplace's Demon accomplishes numerical approximation with Markov chain 
Monte Carlo (MCMC) algorithms.  There are a large number of MCMC 
algorithms, too many to review here.  Popular families (which are often 
non-distinct) include Gibbs sampling, Metropolis-Hastings, Random-Walk 
Metropolis (RWM), slice sampling, and many others, including hybrid 
algorithms.  All MCMC algorithms are known as special cases of the 
Metropolis-Hastings algorithm (Metropolis, et al., 1953).  Regardless of 
the algorithm, the goal in Bayesian inference is to maximize the joint 
posterior distribution and collect samples of the target distributions, 
which are marginal posterior distributions, later to be used for inference.

While designing Laplace's Demon, the primary goal in numerical 
approximation was generalization.  Random-Walk Metropolis (RWM) is widely 
regarded as the most generalizable MCMC algorithm, though it requires that 
the proposal variance is tuned manually.  Gibbs sampling requires 
conditional sampling of conjugate distributions, so it is precluded from 
non-conjugate sampling in its purest form.  Slice sampling samples a 
distribution by sampling uniformly from the region under the plot of its 
density function.  Therefore, it is more appropriate with bounded 
distributions that cannot approach infinity.  There are valid ways to tune 
the RWM algorithm as it updates.  This is known by many names, including 
adaptive Metropolis and adaptive MCMC, among others.  Laplace's Demon uses 
the most generalizable family of MCMC algorithms: RWM and other modified 
forms of it.

\subsection{Block Updating}
Usually, there is more than one target distribution, in which case it must 
be determined whether it is best to sample from target distributions 
individually, in groups, or all at once.  Block updating refers to 
splitting a multivariate vector into groups called blocks, so each block 
may be treated differently.  A block may contain one or more variables.  
Advantages of block updating are that a different MCMC algorithm may be 
used for each block (or variable, for that matter), creating a more 
specialized approach, and the acceptance of a newly proposed state is 
likely to be higher than sampling from all target distributions at once in 
high dimensions.  Disadvantages of block updating are that correlations 
probably exist between variables between blocks, and each block is updated 
while holding the other blocks constant, ignoring these correlations of 
variables between blocks.  Without simultaneously taking everything into 
account, the algorithm may converge slowly or never arrive at the proper 
solution.  Also, as the number of blocks increases, more computation is 
required, which slows the algorithm.  In general, block updating allows a 
more specialized approach at the expense of accuracy, generalization, and 
speed.  Laplace's Demon avoids block updating.

\subsection{Random-Walk Metropolis}
The basic idea of RWM is that each iterative estimate of a parameter is 
part of a changing state, and is influenced only by the previous state.  
The succession of states or iterations constitutes a Markov chain, where 
the current state is influenced only by the previous state.  A proposed 
future estimate, called a proposal, is used to calculate the joint 
posterior density, and a ratio of the proposed to the current joint 
posterior density, called $\alpha$, is compared to a random number drawn 
uniformly from the interval [0,1].  In practice, the log of the joint 
posterior density is used, so $\log(\alpha)$ is the proposal density minus 
the current density.  The proposed state is accepted, replacing the 
current state with probability 1 when the proposed state is an improvement 
over the current state, and may still be accepted if the logarithm of a 
random draw from a uniform distribution is less than $\log(\alpha)$.  
Otherwise, the proposed state is rejected, and the current state is 
repeated so that another proposal may be estimated at the next iteration.  
By comparing $\log(\alpha)$ to the log of a random number when 
$\log(\alpha)$ is not an improvement, random-walk behavior is included in 
the algorithm.

Random-walk behavior is desirable because it allows the algorithm to 
explore, and hopefully avoid getting trapped in undesirable regions.  On 
the other hand, random-walk behavior is undesirable because it takes 
longer to converge to the target distribution while the algorithm 
explores.  The algorithm generally progresses in the right direction, but 
may periodically wander away.  Such exploration may uncover multi-modal 
target distributions, which other algorithms may fail to recognize, and 
then converge incorrectly.  With enough iterations, RWM is guaranteed 
theoretically to converge to the correct target distribution, regardless 
of the starting point of each parameter, provided the proposal variance 
for each proposal is sensible.

Multiple parameters usually exist, and therefore correlations may occur 
between the parameters.  All MCMC algorithms in Laplace's Demon are 
modified to attempt to estimate multivariate proposals, thereby taking 
correlations into account through a covariance matrix.  If a failure is 
experienced in attempting to estimate multivariate proposals, then 
Laplace's Demon temporarily resorts to independent proposals by estimating 
univariate variances, and will continue to attempt to return to 
multivariate proposals at each iteration.

Throughout the RWM algorithm, the proposal covariance or variance remains 
fixed.  The user may enter a vector of proposal variances or a proposal 
covariance matrix, and if neither is supplied, then Laplace's Demon 
estimates both before it begins, based on the number of variables.

The acceptance or rejection of each proposal should be observed at the 
completion of the RWM algorithm as the acceptance rate, which is the 
number of acceptances divided by the total number of iterations.  If the 
acceptance rate is too high, then the proposal variance or covariance is 
too small.  In this case, the algorithm will take longer than necessary to 
find the target distribution and the samples will be highly 
autocorrelated.  If the acceptance rate is too low, then the proposal 
variance or covariance is too large, and the algorithm is ineffective at 
exploration.  In the worst case scenario, no proposals are accepted and 
the algorithm fails to move.  Under theoretical conditions, the optimal 
acceptance rate for a sole, independent and identically distributed (IID), 
Gaussian, marginal posterior distribution is 0.44 or 44\%.  The optimal 
acceptance rate for an infinite number of distributions that are IID and 
Gaussian is 0.234 or 23.4\%.

\subsection{Delayed Rejection Metropolis}
The Delayed Rejection Metropolis (DRM or DR) algorithm is a RWM with one, 
small twist.  Whenever a proposal is rejected, the DRM algorithm will try 
one or more alternate proposals, and correct for the probability of this 
conditional acceptance.  By delaying rejection, autocorrelation in the 
chains may be decreased, and the algorithm is encouraged to move.  
Currently, Laplace's Demon will attempt one alternate proposal when using 
the DRAM (see below) or DRM algorithm.  The additional calculations may 
slow each iteration of the algorithm in which the first set of proposals 
is rejected, but it may also converge faster.  For more information on 
DRM, see Mira (2001).

DRM may be considered to be an adaptive MCMC algorithm, because it adapts 
the proposal based on a rejection.  Here, I have to admit that I don't 
know if DRM violates the Markov property (see below).  For the purposes 
of Laplace's Demon, DRM is not considered to be an adaptive MCMC 
algorithm, because it is not adapting to the target distribution, other 
than making more attempts with the same type of algorithm.  However, if the 
DRM is considered to violate the Markov property (again, see below), then 
its use will be changed here, accordingly.  DRM is rarely suggested by 
Laplace's Demon, though the combination of DRM and AM, called DRAM, is 
suggested frequently.

\subsection{Adaptive Metropolis}
In traditional, non-adaptive RWM, the Markov property is satisfied, 
creating valid Markov chains, but it is difficult to manually optimize the 
proposal variance or covariance, and it is crucial that it is optimized 
for good mixing of the Markov chains.  Adaptive MCMC may be used to 
automatically optimize the proposal variance or covariance based on the 
history of the chains, though this violates the Markov property, which 
declares the proposed state is influenced only by the current state.  To 
retain the Markov property, and therefore valid Markov chains, a two-phase 
approach may be used, in which adaptive MCMC is used in the first phase to 
arrive at the target distributions while violating the Markov property, and 
non-adaptive DRM or RWM is used in the second phase to sample from the 
target distributions for inference, while possessing the Markov property.

There are too many adaptive MCMC algorithms to review here.  All of them 
adapt the proposal variance to improve mixing.  Some adapt the proposal 
variance to also optimize the acceptance rate (which becomes difficult as 
dimensionality increases), minimize autocorrelation, or optimize a scale 
factor.  Laplace's Demon uses a variation of the Adaptive Metropolis (AM) 
algorithm of Haario, Saksman, and Tamminen (2001).

Given the number of dimensions (\textit{d}) or parameters, the optimal 
scale of the proposal variance, also called the jumping kernel, has been 
reported as \texttt{2.4/$\sqrt{d}$} based on the asymptotic limit of 
infinite-dimensional Gaussian target distributions that are independent 
and identically-distributed (Gelman, Roberts, and Gilks, 1996).  In 
applied settings, each problem is different, so the amount of correlation 
varies between variables, target distributions may be non-Gaussian, the 
target distributions may be non-IID, and the scale should be optimized.  
Laplace's Demon uses a scale that is accurate to more decimals: 
$2.381204/\sqrt{d}$, even though Haario et al. use a different form: 
$2.4^2/d$.  There are algorithms in statistical literature that attempt 
to optimize this scale, and it is hoped that these algorithms will be 
included in Laplace's Demon in the future.

Haario et al. (2001) tested their algorithm with up to 200 dimensions or 
parameters, so it is capable of large-scale Bayesian inference.  The 
version in Laplace's Demon should be capable of more dimensions than the 
AM algorithm as it was presented, because when Laplace's Demon experiences 
an error in multivariate AM, it defaults to independent adaptive 
proposals.  Although independent adaptive proposals should take longer to 
converge, the algorithm is limited in dimension only by the RAM of the 
computer.

For multivariate adaptive tuning, the formula across \texttt{K} parameters 
and \texttt{t} iterations is:

$$
\Sigma^* = (\phi_K cov(\theta_[{}_1{}_:{}_t{}_,{}_1{}_:{}_K{}_])) + (\phi_K 1.0E-5\textbf{I}_K)
$$

where $\phi_K$ is the scale according to \texttt{K} parameters, 1.0E-5 is 
a small constant to ensure the proposal covariance matrix is positive 
definite (does not have zero or negative variance on the diagonal), and 
\textbf{I}$_K$ is a \texttt{K} x \texttt{K} identity matrix.  The initial 
proposal covariance matrix, when none is provided, defaults to the scaling 
component multiplied by its identity matrix: $phi_K$\textbf{I}$_K$.

For independent adaptive tuning, the formula across \texttt{K} parameters 
and \texttt{t} iterations is:

$$
\sigma^*{}^2_k = \phi_k var(\theta_[{}_1{}_:{}_t{}_,{}_k{}_]) + \phi_k 1.0E-5
$$

Each element in the initial vector of proposal variances is set equal to 
the asymptotic scale according to its dimensions: $\phi_k$.

In both the multivariate and independent cases, the AM algorithm begins 
with a fixed proposal variance or covariance that is either estimated 
internally or supplied by the user.  Next, the algorithm begins, and it 
does not adapt until the iteration is reached that is specified by the 
user in the \texttt{Adaptive} argument of \LaplacesDemon{}.  Then, the 
algorithm will adapt with every \texttt{n} iterations according to the 
\texttt{Periodicity} argument.  Therefore, the user has control over when 
the AM algorithm begins to adapt, and how often it adapts.  The value of 
the \texttt{Adaptive} argument in Laplace's Demon is chosen subjectively 
by the user according to their confidence in the accuracy of the initial 
proposal covariance or variance.  The value of the \texttt{Periodicity} 
argument is chosen by the user according to their patience: when the value 
is 1, the algorithm will adapt continuously, which will be slower to 
calculate.  The AM algorithm adapts the proposal covariance or variance 
according to the observed covariance or variance in the entire history of 
all parameter chains, as well as the scale factor.

As recommended by Haario, et al. (2001), there are two tricks that may be 
used to assist the AM algorithm in the beginning.  Although Laplace's 
Demon does not use the suggested ``greedy start'' method, it uses the 
second suggested trick of shrinking the proposal as long as the acceptance 
rate is less than 5\%.  Haario, et al. (2001) suggest loosely that if ``it 
has not moved enough during some number of iterations, the proposal could 
be shrunk by a constant factor''.  For each iteration that the acceptance 
rate is less than 5\% and that the AM algorithm is used but the current 
iteration is prior to adaptation, Laplace's Demon multiplies the proposal 
covariance or variance by 99\%.  Over pre-adaptive time, this encourages 
a smaller proposal covariance or variance to increase the acceptance rate 
so that when adaptation begins, the observed covariance or variance of the 
chains will not be constant, and then shrinkage will cease and adaptation 
will take it from there.

\subsection{Delayed Rejection Adaptive Metropolis}
The Delayed Rejection Adaptive Metropolis (DRAM) algorithm is merely the 
combination of both DRM (or DR) and AM (Haario, Laine, Mira, and Saksman,
2006).  DRAM has been demonstrated as robust in extreme situations where 
DRM or AM fail separately.  Haario, et al. (2006) present an example 
involving ordinary differential equations in which least squares could not 
find a stable solution, and DRAM did well.

\subsection{Afterward}
Once the model is updated, the \texttt{Geweke.Diagnostic} function of 
Geweke (1992) is iteratively applied to successively smaller tail-sections 
of the thinned samples to assess stationarity (or lack of trend).  When 
all parameters are estimated as stationary beyond a given iteration, the 
previous iterations are suggested to be considered as burn-in and 
discarded.  The number of thinned samples is divided into cumulative 10\% 
groups, and the \texttt{Geweke.Diagnostic} is applied by beginning with 
each cumulative group.

There is debate in statistical literature over the importance of Monte 
Carlo Standard Error (MCSE).  Here, it is considered important enough to 
be one of five main criteria to appease Laplace's Demon.  Most literature 
recommends using one of several competing batch methods to estimate MCSE, 
arguing that the simple method \texttt{(MCSE = }$\sigma/\sqrt{m}$) 
is biased and reports less error (where \texttt{m} is the effective sample 
size).  I have calculated both the simple method and non-overlapping batch 
MCSE's on a wide range of applied models, and noted just as many cases of 
the simple method producing higher MCSE's as lower MCSE's.  As far as 
Laplace's Demon is concerned, the simple method is used to estimate MCSE, 
but it is open to debate.

\section{Software Comparisons}
There is now a wide variety of software to perform MCMC for Bayesian 
inference.  Perhaps the most common is BUGS, which is an acronym for 
Bayesian Using Gibbs Sampling (Lunn, Spiegelhalter, Thomas, and Best, 
2009).  BUGS has several versions.  A popular variant is JAGS, which is an 
acronym for Just Another Gibbs Sampler (Plummer, 2003).  The only other 
comparisons made here are with some \Rlan{} packages (\texttt{AMCMC}, 
\texttt{mcmc}, \texttt{MCMCpack}, and \texttt{UMACS}) and SAS.  Many other 
\Rlan{} packages use MCMC, but are not intended as general-purpose MCMC 
software.  Hopefully I have not overlooked any general-purpose MCMC 
packages in \Rlan{}.

WinBUGS has been the most common version of BUGS, though it is no longer 
developed.  BUGS is an intelligent MCMC engine that is capable of numerous 
MCMC algorithms, but prefers Gibbs sampling.  According to its user 
manual, WinBUGS 1.4 uses Gibbs sampling with full conditionals that are 
continuous, conjugate, and standard.  For full conditionals that are 
log-concave and non-standard, derivative-free Adaptive Rejection Sampling 
(ARS) is used.  Slice sampling is selected for non-log-concave densities 
on a restricted range, and tunes itself adaptively for 500 iterations.  
Seemingly as a last resort, an adaptive MCMC algorithm is used for 
non-conjugate, continuous, full conditionals with an unrestricted range.  
The standard deviation of the Gaussian proposal distribution is tuned over 
the first 4,000 iterations to obtain an acceptance rate between 20\% and 
40\%.  Samples from the tuning phases of both Slice sampling and adaptive 
MCMC are ignored in the calculation of all summary statistics, although 
they appear in trace-plots.

The current version of BUGS, OpenBUGS, allows the user to specify an MCMC 
algorithm from a long list for each parameter (Lunn et al., 2009).  This 
is a step forward, overcoming what is perceived here as an over-reliance 
on Gibbs sampling.  However, if the user does not customize the selection 
of the MCMC sampler, then Gibbs sampling will be selected for full 
conditionals that are continuous, conjugate, and standard, just as with 
WinBUGS.

Based on years of almost daily experience with WinBUGS and JAGS, which 
are excellent software packages for Bayesian inference, Gibbs sampling is 
selected too often in these automatic, MCMC engines.  A suggestion for 
BUGS and JAGS would be to attempt Gibbs sampling and abandon it if 
correlations are too high.  An advantage of Gibbs sampling is that the 
proposals are accepted with probability 1, so convergence may be faster.  
Unfortunately, Gibbs sampling is not as generalizable, because it can 
function only when certain conjugate distributional forms are known 
\textit{a priori}.  Moreover, Gibbs sampling was avoided for Laplace's 
Demon because it doesn't perform well with correlated variables or 
parameters, which usually exist, and I have been bitten by that 
\textit{bug} many times.

The BUGS and JAGS families of MCMC software are excellent.  BUGS is 
capable of several things that Laplace's Demon is not.  For example, BUGS 
automatically handles missing values in the dependent variable, where 
Laplace's Demon requires specifications for each one in the \texttt{Model} 
function.  BUGS also allows the user to specify the model graphically as a 
directed acyclic graph (DAG) in Doodle BUGS.  Lastly, many textbooks in 
several fields have been written that are full of WinBUGS examples.

The four MCMC algorithms in Laplace's Demon are generalizable, and 
generally robust to correlation between variables or parameters.  The 
disadvantage is slower convergence when correlations are low.  The 
advantages, however, are faster convergence when correlations are high, 
and more confidence in the results.  

At the time this article was written, the \texttt{AMCMC} package in 
\Rlan{} is unavailable on CRAN, but may be downloaded from the author's 
website.  This download is best suited for a Linux, Mac, or UNIX operating 
system, because it requires the \texttt{gcc} C compiler, which is 
unavailable in Windows.  It performs adaptive Metropolis-within-Gibbs 
(Roberts and Rosenthal, 2007), and uses C language for significantly 
faster sampling.  Metropolis-within-Gibbs is not as generalizable as 
adaptive MCMC.  Otherwise, if the user wishes to see the code of the 
\texttt{AMCMC} sampler, then the user must also be familiar with C 
language.

Also in \Rlan{}, the \texttt{mcmc} package offers RWM with multivariate 
Gaussian proposals and allows batching, as well as a simulated tempering 
algorithm, but it does not have any adaptive algorithms.

The \texttt{MCMCpack} package in \Rlan{} takes a canned-function approach 
to RWM, which is convenient if the user needs the specific form provided, 
but is otherwise not generalizable.  General-purpose RWM is included, but 
adaptive algorithms are not.  It also offers the option of Laplace 
Approximation to optimize initial values, though the algorithm is 
evaluated in \texttt{optim}, which has not performed well in my testing of 
Laplace Approximations.

At the time this article was written, Gelman's \texttt{UMACS} package has 
been removed from CRAN.  It became outdated due to lack of interest, and 
did not include an adaptive MCMC algorithm, as far as I know.

In SAS 9.2, an experimental procedure called PROC MCMC has been 
introduced.  It is undeniably a rip-off of BUGS (including its syntax), 
though OpenBUGS is much more powerful, tested, and generalizable.  Since 
SAS is proprietary, the user cannot see or manipulate the source code, and 
should expect much more from it than OpenBUGS or any open-source software, 
given the absurd price.

\section{Large Data Sets and Speed}
An advantage of Laplace's Demon compared to other MCMC software is that 
the model is specified in a way that takes advantage of \Rlan{}'s 
vectorization.  BUGS and JAGS, for example, require models to be specified 
so that each record of data is processed one by one inside a 'for loop', 
which significantly slows updating with larger data sets.  In contrast, 
Laplace's Demon avoids 'for loops' wherever possible.  For example, a data 
set of 100,000 rows and 16 columns (the dependent variable, a column 
vector of 1's for the intercept, and 14 predictors) was updated 1,000 
times with \texttt{Adaptive=2}, \texttt{DR=0}, and \texttt{Periodicity=10} 
in 1.55 minutes by Laplace's Demon, according to a simple, linear 
regression\footnote{These updates were performed on a 2010 System76 
Pangolin Performance laptop with 64-bit Debian Linux and 8GB RAM.}.  It 
was nowhere near convergence, but try to run 100,000 rows of comparable 
data for 1,000 iterations in BUGS or JAGS, and tell me how long it took!

However, with small data sets, other MCMC software (\texttt{AMCMC} is a 
good example) can be faster than Laplace's Demon, if it is programmed in a 
faster language such as Component Pascal, C, or C++.  I have not studied 
all MCMC algorithms in \Rlan{}, but most are probably programmed in C and 
called from \Rlan{}.  And Laplace's Demon could be much faster if 
programmed in C as well.

When the non-adaptive algorithm updates in Laplace's Demon, the expected 
speed of an iteration should not differ depending on how many iterations 
it has previously updated.  However, the adaptive algorithm will slow as 
iterations are updated, because each time it adapts, it is adapting to the 
covariance of the entire history of the chains.  As the history increases, 
the calculations take longer to complete, and the expected speed of an 
adaptive iteration decreases, compared to earlier adaptive iterations.  If 
time is of the essence and the algorithm needs to be adaptive, then it may 
be best to make multiple, shorter updates in place of one, longer update.

\section{Future Goals}
Laplace's Demon is useful software for Bayesian inference.  Nonetheless, 
there are several future goals to improve it.  There are a bewildering 
number of methods for numerical approximation.  For example, not only are 
there a large number of MCMC algorithms, some of which are newer and take 
additional things into account, there are other methods of approximation, 
including Laplace Approximation (also called Laplace's Method), Expectation 
Maximization (EM) and Variational Bayes, Approximate Bayesian Computation 
(ABC), and other methods such as iterative quadrature.

Currently, Laplace's Demon offers custom variations of four MCMC 
algorithms.  It is likely that future versions of Laplace's Demon will 
include other MCMC algorithms for the user to select.  Additionally, a 
deterministic algorithm such as Laplace Approximation may become optional 
to initially approximate the solution prior to using MCMC, thus 
speeding convergence.

To this end, I have not yet found a generalizable Laplace Approximation 
algorithm.  Laplace Approximation is available as the \texttt{laplace} 
function in the \texttt{LearnBayes} package, and also as an option in the 
\texttt{MCMCpack} package for some MCMC models.  Both functions are solved 
with the \texttt{optim} function of base \Rlan{}, and both exhibit error 
that increases unacceptably with the number of parameters, usually beyond 
6.  Using the \texttt{BB} package for optimization, I have been able to 
accurately estimate approximately 60 parameters in a simple model.

It is possible that the algorithms may also be included in C language, so 
the user can select whichever language is preferred, probably C for speed.  
Last but not least, I'm sure my \Rlan{} code could be more efficient.

Please send all constructive criticism and reports of software bugs to 
\texttt{statisticat@gmail.com}.

\section{References}

Bayes, T. and Price, R. (1763). An Essay towards solving a Problem in the 
Doctrine of Chance. By the late Rev. Mr. Bayes, communicated by Mr. Price, 
in a letter to John Canton, M. A. and F. R. S. Philosophical Transactions 
of the Royal Society of London, 53, p. 370--418.

Crawley, M.J. (2007). \uline{The R Book}. John Wiley \& Sons Ltd: West 
Sussex, England.

Gelman, A. (2008). Scaling Regression Inputs by Dividing by Two Standard 
Deviations. Statistics in Medicine, 27, p. 2865--2873.

Gelman, A., Carlin, J.B., Stern, H.S., and Rubin, D. (2004). 
\uline{Bayesian Data Analysis}, Second Edition. Chapman \& Hall: Boca 
Raton, FL.

Gelman, A., Meng, X.L., and Stern, H. (1996). Posterior Predictive 
Assessment of Model Fitness via Realized Discrepancies. Statistica Sinica, 
6, p. 733--807.

Gelman, A., Roberts, G.O., and Gilks, W.R. (1996). Efficient Metropolis 
Jumping Rules. Bayesian Statistics, 5, p. 599--608.

Geweke, J. (1992). Evaluating the Accuracy of Sampling-Based Approaches to 
the Calculation of Posterior Moments. Bayesian Statistics, 4, p. 1--31.

Haario, H., Laine, M., Mira, A., and Saksman, E. (2006). DRAM: Efficient
Adaptive MCMC. Statistical Computing, 16, p. 339--354.

Haario, H., Saksman, E., and Tamminen, J. (2001). An Adaptive Metropolis
Algorithm. Bernouli, 7(2), p. 223--242.

Laplace, P.S. (1774). Memoire sur la probabilite des causes par les
evenements.  Mem. Acad. Sci. Paris, 6, 621--656.  English translation in
1986 as ``Memoir on the probability of the causes of events'', Statist.
Sci., 1, p. 359--378.

Laplace, P.S. (1812). \uline{Theorie Analytique des Probabilites}. Paris: 
Courcier. Reprinted as Oeuvres Completes de Laplace, 7, 1878--1912. Paris: 
Gauthier-Villars.

Laplace, P.S. (1814). Essai philosophique sur les probabilites. English 
translation in 1902 as ``A Philosophical Essay on Probabilities''.

Lunn, D., Spiegelhalter, D., Thomas, A., and Best, N. (2009). The BUGS 
project: Evolution, critique, and future directions.  Statistics in 
Medicine, 28, p. 3049--3067.

Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., and Teller, E. (1953). 
Equation of State Calculations by Fast Computing Machines. Journal of 
Chemical Physics, 21, p. 1087--1092.

Mira, A. (2001). On Metropolis-Hastings Algorithms with Delayed Rejection. 
Metron, Vol. LIX, n. 3--4, p. 231--241.

Plummer, M. (2003). JAGS: A Program for Analysis of Bayesian Graphical 
Models Using Gibbs Sampling. Proceedings of the 3rd International Workshop 
on Distributed Statistical Computing (DSC 2003), March 20--22, Vienna, 
Austria. ISBN 1609--395X. 

R Development Core Team (2010). R: A language and environment for 
statistical computing. R Foundation for Statistical Computing, Vienna, 
Austria. ISBN 3--900051--07--0, URL \url{http://www.R-project.org/}.

Roberts, G.O., and Rosenthal, J.S. (2007). Examples of Adaptive MCMC. 
Comp. Stat. \& Data Anal., 51, p. 5467--5470.

\end{document}
